{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist  # MNIST data\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy #loss function\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD #optimisers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] MNIST - Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits in the MNIST dataset are in the center. Here we will undo this operation and compare the performance of convolutional neural networks vs fully connected networks.  \n",
    "* Create a new dataset of size 50x50 where you place the handwritten digit at different random positions in the dataset.\n",
    "* Now train a neural network with a single hidden dense layer (as on the original MNIST dataset in the lectures).\n",
    "* Now try to improve your performance in comparison to your previous layout by using an architecture involving convolutional layers (Conv2D).\n",
    "* $\\star$ We have mentioned various options to improve the performance of networks. Check whether methods like Dropout, BatchNormalization, Pooling layers can improve your results. Try to fine-tune the performance (you may also try deeper architectures, i.e. with more hidden layers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a very accessible explanation of CNNs, see e.g. [link](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/).  \n",
    "\n",
    "You can have a look at some architectures in the literature:  \n",
    "[LeNet5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)  \n",
    "[GoogLeNet](https://arxiv.org/pdf/1409.4842.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also: [Why is training loss higher than testing loss?](https://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss)  \n",
    "Very useful when training takes long: [Keras Callbacks](https://keras.io/callbacks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun stuff about fruit flies: [link](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0205043)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy code from lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some code for random positioning in a 50x50 initialized with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picx = 28\n",
    "picy = 28\n",
    "bigpicx = 50\n",
    "bigpicy = 50\n",
    "\n",
    "def embed(pic, pos):\n",
    "    # pos expects a tuple of slice objects\n",
    "    bigpic = np.zeros((bigpicx, bigpicy))\n",
    "    bigpic[pos] = pic\n",
    "    return bigpic\n",
    "\n",
    "def randpos():\n",
    "    xpos = np.random.randint(0, (bigpicx-picx))\n",
    "    ypos = np.random.randint(0, (bigpicy-picy))\n",
    "    # we use np.s_ to return a tuple of slice objects\n",
    "    return np.s_[xpos:xpos+picx, ypos:ypos+picy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final processing of the data is quite compact using list comprehensions\n",
    "x_train_original = x_train\n",
    "x_test_original = x_test\n",
    "x_train = np.array([embed(pic, randpos()) for pic in x_train])\n",
    "x_test = np.array([embed(pic, randpos()) for pic in x_test])\n",
    "x_train_conv = np.expand_dims(x_train, axis=3)\n",
    "x_test_conv = np.expand_dims(x_test, axis=3)\n",
    "x_train_original_conv = np.expand_dims(x_train_original, axis=3)\n",
    "x_test_original_conv = np.expand_dims(x_test_original, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with only dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model1.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "hist1 = model1.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist1.history['acc'])\n",
    "plt.plot(hist1.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist1.history['loss'])\n",
    "plt.plot(hist1.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not bad, training is fast, but it is hard to go significantly beyond 90% accuracy on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now also add convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1 = tf.keras.Sequential()\n",
    "\n",
    "# Convolutional preprocessing\n",
    "model_conv1.add(tf.keras.layers.Conv2D(16, (5,5), input_shape=(50,50,1), activation='relu'))\n",
    "model_conv1.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "model_conv1.add(tf.keras.layers.Conv2D(16, (5,5), input_shape=(50,50,1), activation='relu'))\n",
    "model_conv1.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Flatten to prepare for dense layers\n",
    "model_conv1.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Dense postprocessing\n",
    "model_conv1.add(tf.keras.layers.Dense(648, activation='relu'))\n",
    "\n",
    "model_conv1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model_conv1.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "hist_conv1 = model_conv1.fit(x_train_conv, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_conv, y_test))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist_conv1.history['acc'])\n",
    "plt.plot(hist_conv1.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist_conv1.history['loss'])\n",
    "plt.plot(hist_conv1.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv2 = tf.keras.Sequential()\n",
    "\n",
    "# Convolutional preprocessing\n",
    "model_conv2.add(tf.keras.layers.Conv2D(64, (7,7), input_shape=(50,50,1), activation='relu'))\n",
    "model_conv2.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
    "model_conv2.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model_conv2.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
    "model_conv2.add(tf.keras.layers.Conv2D(192, (3,3), activation='relu'))\n",
    "model_conv2.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Flatten to prepare for dense layers\n",
    "model_conv2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Dense postprocessing\n",
    "model_conv2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "model_conv2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model_conv2.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_conv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "\n",
    "hist_conv2 = model_conv2.fit(x_train_conv, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_conv, y_test))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist_conv2.history['acc'])\n",
    "plt.plot(hist_conv2.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist_conv2.history['loss'])\n",
    "plt.plot(hist_conv2.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add batch normalization and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv3 = tf.keras.Sequential()\n",
    "\n",
    "# Convolutional preprocessing\n",
    "model_conv3.add(tf.keras.layers.Conv2D(64, (7,7), input_shape=(50,50,1), use_bias=False))\n",
    "model_conv3.add(tf.keras.layers.BatchNormalization())\n",
    "model_conv3.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.Conv2D(128, (3,3), use_bias=False))\n",
    "model_conv3.add(tf.keras.layers.BatchNormalization())\n",
    "model_conv3.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.MaxPooling2D(pool_size=3))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.Conv2D(192, (3,3), use_bias=False))\n",
    "model_conv3.add(tf.keras.layers.BatchNormalization())\n",
    "model_conv3.add(tf.keras.layers.Activation('relu'))\n",
    "model_conv3.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Flatten to prepare for dense layers\n",
    "model_conv3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Dense postprocessing\n",
    "model_conv3.add(tf.keras.layers.Dense(128, use_bias=False))\n",
    "model_conv3.add(tf.keras.layers.BatchNormalization())\n",
    "model_conv3.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "model_conv3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model_conv3.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_conv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "\n",
    "hist_conv3 = model_conv3.fit(x_train_conv, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_conv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist_conv3.history['acc'])\n",
    "plt.plot(hist_conv3.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist_conv3.history['loss'])\n",
    "plt.plot(hist_conv3.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to familiarise yourself with analysing tools for trained neural networks, i.e. opening the black box. In Keras you can access the value of the weights using get weights(). Here we analyse the network we have discussed in the lectures, you can find a link to the pre-trained weights on the course website.  \n",
    "* In a first step, identify examples where the network is not yet performing well, i.e. which are incorrectly classified.\n",
    "* In a second step, visualise the average activation of several hidden layers and in particular different hidden filters in the convolutional layers. Try to identify the role of some of the hidden filters. It might be useful to consider the activations for a particular class of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at what Google does!  \n",
    "[DeepDream Blog Post](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)  \n",
    "[DeepDream Github](https://github.com/google/deepdream/blob/master/dream.ipynb)  \n",
    "Also have a look at this [link](https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030) for maximizing activation of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CIFAR dataset\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from downloaded file\n",
    "model2 = tf.keras.models.load_model('keras_cifar10_trained_model.h5')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only a few\n",
    "predictions = model2.predict_classes(x_test[:100])\n",
    "correct_classes = np.argwhere(y_test==1)[:100,1]\n",
    "\n",
    "wrong_pred = x_test[:100][predictions != correct_classes]\n",
    "wrong_pred_predicted_classes = predictions[predictions != correct_classes]\n",
    "wrong_pred_correct_classes = correct_classes[predictions != correct_classes]\n",
    "wrong_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one example:\n",
    "\n",
    "examplenum = 0\n",
    "\n",
    "plt.imshow(wrong_pred[examplenum], interpolation='nearest')\n",
    "plt.title(\"predicted: \" + str(wrong_pred_predicted_classes[examplenum]) + \"   \" + \"should have been: \" + str(wrong_pred_correct_classes[0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the layer outputs of model2\n",
    "layer_outputs = [layer.output for layer in model2.layers] \n",
    "\n",
    "# Create model that spits out the outputs of model2\n",
    "model_out = tf.keras.models.Model(inputs=model2.input, outputs=layer_outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the wrong predictions\n",
    "activations = model_out.predict(wrong_pred[examplenum].reshape(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "# have a look at different feature maps\n",
    "plt.matshow(first_layer_activation[0, :, :, 0], cmap='inferno')\n",
    "plt.matshow(first_layer_activation[0, :, :, 1], cmap='inferno')\n",
    "plt.matshow(first_layer_activation[0, :, :, 2], cmap='inferno')\n",
    "plt.matshow(first_layer_activation[0, :, :, 3], cmap='inferno')\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all layer activations in the convolutional part of the net\n",
    "def plot_layers(examplenum = 0):\n",
    "    activations = model_out.predict(wrong_pred[examplenum].reshape(-1,32,32,3))\n",
    "\n",
    "    layer_names = []\n",
    "    for layer in model2.layers:\n",
    "        # Get layer names for plot titles\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "    images_per_row = 16\n",
    "    \n",
    "# The code below looks complicated, but its just about the presentation and plotting.\n",
    "# You might as well ignore it.\n",
    "# The essence of how we extract the activations was already shown above.\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        if len(layer_activation.shape) == 4:     # ignore dense layers\n",
    "            # number of feature maps\n",
    "            n_features = layer_activation.shape[-1]\n",
    "            # layer_activation.shape -> (1, size, size, n_features)\n",
    "            size = layer_activation.shape[1]\n",
    "            # arange in grid\n",
    "            n_cols = n_features // images_per_row\n",
    "            display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "            for col in range(n_cols):\n",
    "                for row in range(images_per_row):\n",
    "                    channel_image = layer_activation[0,:,:, col * images_per_row + row]\n",
    "                    # post processing\n",
    "                    channel_image -= channel_image.mean()\n",
    "                    channel_image /= channel_image.std()\n",
    "                    channel_image *= 64\n",
    "                    channel_image += 128\n",
    "                    channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                    # place into grid\n",
    "                    display_grid[col*size:(col+1)*size, row*size:(row+1)*size] = channel_image\n",
    "            scale = 1. / size\n",
    "            plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0]))\n",
    "            plt.title(layer_name)\n",
    "            plt.grid(False)\n",
    "            plt.imshow(display_grid, aspect='auto', cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
