{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfbg_NxOEZ-k"
   },
   "source": [
    "# Exercise Sheet 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HYjFWp2EZ-o"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgzAZA0EEZ_A"
   },
   "source": [
    "## GAN Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDNkoCxqEZ_C"
   },
   "source": [
    "For the example $V(x, y) = x y$ perform alternating gradient descent updates with respect to $x$ and $y$ as we would perform when training a GAN, i.e. one player is performing updates to optimise $V$ and one player to optimise $−V$. Identify the trajectory of this update. Which ‘late-time’ behaviour do you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDcKpLVOEZ_D"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvOD0QpxVuKP"
   },
   "source": [
    "First we see what happens when both players update with respect to the full gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKqDnXCsfE3T"
   },
   "outputs": [],
   "source": [
    "# X = [x, y]\n",
    "V = lambda X: X[0] * X[1]\n",
    "Vneg = lambda X: -V(X)\n",
    "dV = lambda X: np.array([X[1], X[0]])\n",
    "dVneg = lambda X: -dV(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNe47-FDeGD7"
   },
   "outputs": [],
   "source": [
    "def alt_grad_descent1(epochs, lrate):\n",
    "    X = np.random.normal(0,10,2)\n",
    "    hist = np.zeros([epochs ,2])\n",
    "    for j in range(epochs):\n",
    "        # minimize V\n",
    "        X = X - lrate*dV(X)\n",
    "        # minimize -V\n",
    "        X = X - lrate*dVneg(X)\n",
    "        hist[j] = X\n",
    "    return hist\n",
    "\n",
    "hist = alt_grad_descent1(50000, 10**-2)\n",
    "Vhist = [V(hist[i]) for i in range(len(hist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "BQCgGZXzPbj9",
    "outputId": "e380c8ba-25d7-4f48-b5a4-98b4a6a5985b"
   },
   "outputs": [],
   "source": [
    "plt.plot(Vhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "mGpx-aryqvbb",
    "outputId": "63e522b2-9ed7-4a28-f340-07e532d286ef"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist[:,0], hist[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xS0YXqAiV3Bt"
   },
   "source": [
    "Now we check what happens when player 1 updates only the x-direction, while player 2 updates only the y-direction. See [here](https://arxiv.org/pdf/1801.04406.pdf) for the relation to GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "os6jB8-GWBKw"
   },
   "outputs": [],
   "source": [
    "def alt_grad_descent2(epochs, lrate):\n",
    "    X = np.random.normal(0,10,2)\n",
    "    hist = np.zeros([epochs ,2])\n",
    "    for j in range(epochs):\n",
    "        # minimize V\n",
    "        X[0] = X[0] - lrate*dV(X)[0]\n",
    "        # minimize -V\n",
    "        X[1] = X[1] - lrate*dVneg(X)[1]\n",
    "        hist[j] = X\n",
    "    return hist\n",
    "\n",
    "hist = alt_grad_descent2(50000, 10**-3)\n",
    "Vhist = [V(hist[i]) for i in range(len(hist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "qCNM_aGDWO8j",
    "outputId": "c4057f03-6e81-4ce1-d2bb-19c64e1d0437"
   },
   "outputs": [],
   "source": [
    "plt.plot(Vhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Fk4ZcO1aWVSb",
    "outputId": "d6c116f7-f2b7-467b-9128-e92c7f8391f1"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist[:,0], hist[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnawiBWUs_5V"
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuwPFkkNs_5Y"
   },
   "source": [
    "The aim of this exercise is to implement a GAN architecture and to test it on the polynomial dataset from the previous exercise sheets. You can adapt the architecture from the MNIST example in the lectures.  \n",
    "$\\star$ Update your loss function to implement a Wasserstein GAN.  \n",
    "Note that in case you do not have a local environment where you can calculate on a GPU, you can calculate online on collab on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsTG_su8XDoj"
   },
   "source": [
    "The references are: [GAN](https://arxiv.org/abs/1406.2661), [WGAN](https://arxiv.org/abs/1701.07875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPWdYWQls_5Z"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8AkzCKKVpZd"
   },
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJv2sUfHpPWv"
   },
   "outputs": [],
   "source": [
    "# Polynomial data\n",
    "\n",
    "size = 40\n",
    "\n",
    "# evaluate polynomial over grid of size 40x40\n",
    "def polynomial(degree):\n",
    "    coeff = np.random.normal(0,1,(degree+1, degree+1))\n",
    "    #coeff = np.random.uniform(-1,1,(degree+1, degree+1))\n",
    "    return [[sum([coeff[i,j]*((x/size)**i)*((y/size)**j)\n",
    "            for i in range(degree+1) for j in range(degree+1) if (i+j)<=degree]) \n",
    "            for x in range(size)] for y in range(size)]\n",
    "\n",
    "# training set of polynomial images of degree <=5\n",
    "maxdegree = 5\n",
    "size = 40\n",
    "num_polys = 20000\n",
    "polydata = np.array([polynomial(np.random.randint(0,maxdegree)) for i in range(num_polys)])\n",
    "polydata = tf.keras.utils.normalize(polydata)\n",
    "np.save('polydata.npy', polydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dROAjd5Tpo0O"
   },
   "outputs": [],
   "source": [
    "polydata = np.load('polydata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "B2HGmBMMc-Q-",
    "outputId": "b74646aa-26ec-4e31-d549-0762cd38caa9"
   },
   "outputs": [],
   "source": [
    "plt.imshow(polydata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7nUTkLKCj0_M",
    "outputId": "be7d7bfe-f51a-4181-b74d-0a38f7098336"
   },
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 40\n",
    "        self.img_cols = 40\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 2\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 10 * 10, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((10, 10, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        # (X_train, _), (_, _) = mnist.load_data()\n",
    "        X_train = polydata\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        # X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/poly_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "dcgan.train(epochs=4000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "guZ22DU3rbRo",
    "outputId": "8985c31d-d627-4d98-c443-28c85682c131"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 8, figsize=(19,5))\n",
    "for i in range(2):\n",
    "  for j in range(8):\n",
    "    out = dcgan.generator.predict(np.reshape(np.random.normal(0,1,2),(1,2)))\n",
    "    axes[i,j].imshow(out[0,:,:,0])\n",
    "    \n",
    "fig, axes = plt.subplots(2, 8, figsize=(19,5))\n",
    "for i in range(2):\n",
    "  for j in range(8):\n",
    "    axes[i,j].imshow(polydata[i*j+j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luLhXLGlhElx"
   },
   "source": [
    "#### Wasserstein GAN  \n",
    "[Paper](https://arxiv.org/pdf/1701.07875.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s6bNbndrG9jR",
    "outputId": "207e843f-f261-478f-b944-fee92eb7612c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 40\n",
    "        self.img_cols = 40\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 10\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 10\n",
    "        self.clip_value = 0.03\n",
    "        optimizer = RMSprop(lr=0.00003)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 10 * 10, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((10, 10, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        x=8\n",
    "        model.add(Conv2D(x*16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(x*32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(x*64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(x*128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        # (X_train, _), (_, _) = mnist.load_data()\n",
    "        X_train = polydata\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        # X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = -np.ones((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            self.critic.trainable = True\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                \n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the critic\n",
    "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                # Clip critic weights\n",
    "                for l in self.critic.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            #self.critic.trainable = False\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            #print(epoch)\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/wgan_poly_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "wgan.train(epochs=4000, batch_size=32, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "1fF8hLgfiuV9",
    "outputId": "2e256503-e43d-43fc-f6e8-521bafc32731"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 8, figsize=(19,5))\n",
    "for i in range(2):\n",
    "    for j in range(8):\n",
    "        out = wgan.generator.predict(np.reshape(np.random.normal(0,1,10),(1,10)))\n",
    "        axes[i,j].imshow(out[0,:,:,0])\n",
    "    \n",
    "fig, axes = plt.subplots(2, 8, figsize=(19,5))\n",
    "for i in range(2):\n",
    "    for j in range(8):\n",
    "        axes[i,j].imshow(polydata[i*j+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3l2L3-YX5U28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SolutionExercise9.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
